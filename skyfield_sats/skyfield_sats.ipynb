{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727af47e-83b7-4f27-9399-c71d64e6ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyfield.api import load\n",
    "from skyfield.api import wgs84\n",
    "import numpy as np\n",
    "from hilbertcurve.hilbertcurve import HilbertCurve\n",
    "import psycopg2\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Load TLE data\n",
    "def get_starlink_satellites(url=\"https://celestrak.org/NORAD/elements/gp.php?GROUP=starlink&FORMAT=tle\"):\n",
    "    print(\"Loading TLE data...\")\n",
    "    satellites = load.tle_file(url)\n",
    "    satellites = [{\"sat\":s} for s in satellites]\n",
    "    print(f\"Loaded {len(satellites)} Starlink satellites.\")\n",
    "    return satellites\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "def connect_to_db():\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"minecraftindex\",\n",
    "        user=\"kyjohnso\",\n",
    "        password=\"Password\",\n",
    "        host='localhost',  # Use the service name from docker-compose.yml\n",
    "        port=5432\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "# Compute ECEF XYZ positions\n",
    "def compute_ecef_positions(satellites):\n",
    "    ts = load.timescale()\n",
    "    now = ts.now()\n",
    "\n",
    "    for sat in satellites:\n",
    "        try:\n",
    "            geocentric = sat[\"sat\"].at(now)\n",
    "            subpoint = wgs84.subpoint(geocentric)\n",
    "\n",
    "            # Get ECEF XYZ coordinates\n",
    "            sat.update({\n",
    "                \"scc\": sat[\"sat\"].model.satnum,\n",
    "                \"name\": sat[\"sat\"].name,\n",
    "                \"ecef\": geocentric.position.m,\n",
    "                \"timestamp\": now.utc_datetime()\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error computing position for {sat.name}: {e}\")\n",
    "\n",
    "    return satellites\n",
    "\n",
    "# Insert satellite data into the database\n",
    "def ecef_points_to_hilbert(ecef,hilbert_dict):\n",
    "    \n",
    "    p=hilbert_dict.get(\"p\",np.ceil(np.log2(hilbert_dict[\"world_size\"]/hilbert_dict[\"cell_size\"])))\n",
    "    hilbert_dict[\"p\"] = p\n",
    "    ecef_scale = (\n",
    "        ecef + hilbert_dict[\"world_size\"]/2\n",
    "    )/hilbert_dict[\"cell_size\"]\n",
    "    ecef_scale_int = ecef_scale.astype(np.int64)\n",
    "\n",
    "    hilbert_curve = HilbertCurve(\n",
    "        n=hilbert_dict.get(\"n\",3),\n",
    "        p=p\n",
    "    )\n",
    "\n",
    "    return hilbert_curve.distances_from_points(ecef_scale_int)\n",
    "\n",
    "def hilbert_to_ecef_points(hilbert,hilbert_dict):\n",
    "    p=hilbert_dict.get(\"p\",np.ceil(np.log2(hilbert_dict[\"world_size\"]/hilbert_dict[\"cell_size\"])))\n",
    "    \n",
    "    hilbert_curve = HilbertCurve(\n",
    "        n=hilbert_dict.get(\"n\",3),\n",
    "        p=p\n",
    "    )\n",
    "    \n",
    "    ecef_scale = hilbert_curve.points_from_distances(hilbert)\n",
    "\n",
    "    return np.array(ecef_scale) * hilbert_dict[\"cell_size\"] - hilbert_dict[\"world_size\"]/2\n",
    "\n",
    "def add_hilbert_to_satellites(satellites,hilbert):\n",
    "    for i in range(len(satellites)):\n",
    "        satellites[i][\"hilbert_index\"]=hilbert[i]\n",
    "    return satellites\n",
    "\n",
    "def create_satellites_table(conn):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Create the table if it doesn't exist\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS satellites (\n",
    "            id SERIAL PRIMARY KEY,                   -- Auto-incrementing primary key\n",
    "            satnum INT NOT NULL,                     -- Satellite number (cannot be NULL)\n",
    "            ecef GEOMETRY(POINTZ, 4978) NOT NULL,    -- 3D ECEF coordinates (cannot be NULL)\n",
    "            observation_time TIMESTAMP NOT NULL,     -- Observation timestamp (cannot be NULL)\n",
    "            name TEXT NOT NULL,                      -- Satellite name (cannot be NULL)\n",
    "            hilbert_index BIGINT NOT NULL,           -- Hilbert curve index (cannot be NULL),\n",
    "            CONSTRAINT satnum_time_hilbert_unique UNIQUE (satnum, observation_time, hilbert_index) -- Optional uniqueness constraint\n",
    "        );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    cursor.execute(\"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS satnum_time_idx_compound\n",
    "            ON satellites (satnum, observation_time, hilbert_index);\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    cursor.execute(\"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS time_idx_compound\n",
    "            ON satellites (observation_time, hilbert_index);\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    cursor.execute(\"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS satnum_idx_compound\n",
    "            ON satellites (satnum, hilbert_index);\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    cursor.execute(\"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS idx\n",
    "            ON satellites (hilbert_index);\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "def drop_satellites_table(connection):\n",
    "    \"\"\"\n",
    "    Drops the satellites table if it exists in a PostgreSQL database.\n",
    "\n",
    "    Args:\n",
    "        connection (psycopg2.extensions.connection): Active database connection.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    drop_table_query = \"DROP TABLE IF EXISTS satellites CASCADE;\"\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # Execute the drop table query\n",
    "            cursor.execute(drop_table_query)\n",
    "            # Commit the transaction\n",
    "            connection.commit()\n",
    "            print(\"Satellites table dropped successfully.\")\n",
    "    except Exception as e:\n",
    "        connection.rollback()\n",
    "        print(f\"Error dropping satellites table: {e}\")\n",
    "\n",
    "def create_hilbert_points_table(connection):\n",
    "    \"\"\"\n",
    "    Creates the hilbert_points table with hilbert_index as the primary key\n",
    "    and a corresponding 3D point entry.\n",
    "\n",
    "    Args:\n",
    "        connection (psycopg2.extensions.connection): Active database connection.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS hilbert_points (\n",
    "        hilbert_index BIGINT PRIMARY KEY,       -- Hilbert index as the primary key\n",
    "        point GEOMETRY(POINTZ, 4978) NOT NULL  -- 3D point (ECEF coordinates) with SRID 4978\n",
    "    );\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # Execute the create table query\n",
    "            cursor.execute(create_table_query)\n",
    "            # Commit the transaction\n",
    "            connection.commit()\n",
    "            print(\"Hilbert points table created successfully.\")\n",
    "    except Exception as e:\n",
    "        connection.rollback()\n",
    "        print(f\"Error creating hilbert points table: {e}\")\n",
    "\n",
    "def drop_hilbert_points_table(connection):\n",
    "    \"\"\"\n",
    "    Drops the hilbert_points table if it exists in the database.\n",
    "\n",
    "    Args:\n",
    "        connection (psycopg2.extensions.connection): Active database connection.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    drop_table_query = \"DROP TABLE IF EXISTS hilbert_points CASCADE;\"\n",
    "    \n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # Execute the drop table query\n",
    "            cursor.execute(drop_table_query)\n",
    "            # Commit the transaction\n",
    "            connection.commit()\n",
    "            print(\"Hilbert points table dropped successfully.\")\n",
    "    except Exception as e:\n",
    "        connection.rollback()\n",
    "        print(f\"Error dropping hilbert points table: {e}\")\n",
    "\n",
    "def insert_hilbert_points(hilbert_points, connection):\n",
    "    \"\"\"\n",
    "    Inserts a list of hilbert points into the hilbert_points table.\n",
    "\n",
    "    Args:\n",
    "        connection (psycopg2.extensions.connection): Active database connection.\n",
    "        hilbert_points (list of dict): List of dictionaries containing:\n",
    "            - hilbert (int): Hilbert index.\n",
    "            - ecef (tuple): Tuple of ECEF coordinates (x, y, z) in meters.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO hilbert_points (hilbert_index, point)\n",
    "    VALUES (%s, ST_SetSRID(ST_MakePoint(%s, %s, %s), 4978))\n",
    "    ON CONFLICT (hilbert_index) DO NOTHING;\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # Prepare data for batch insertion\n",
    "            data = [\n",
    "                (\n",
    "                    point[\"hilbert\"], \n",
    "                    str(point[\"ecef\"][0]), \n",
    "                    str(point[\"ecef\"][1]), \n",
    "                    str(point[\"ecef\"][2]),\n",
    "                )\n",
    "                for point in hilbert_points\n",
    "            ]\n",
    "            # Execute batch insertion\n",
    "            cursor.executemany(insert_query, data)\n",
    "            # Commit the transaction\n",
    "            connection.commit()\n",
    "            print(f\"{len(hilbert_points)} hilbert points inserted successfully.\")\n",
    "    except Exception as e:\n",
    "        connection.rollback()\n",
    "        print(f\"Error inserting hilbert points: {e}\")\n",
    "\n",
    "\n",
    "def insert_satellites(satellites, connection):\n",
    "\n",
    "    with connection.cursor() as cursor:\n",
    "        # Insert the data\n",
    "        for sat in satellites:\n",
    "            insert_query = \"\"\"\n",
    "                INSERT INTO satellites (satnum, ecef, observation_time, name, hilbert_index)\n",
    "                VALUES (%s, ST_SetSRID(ST_MakePoint(%s, %s, %s), 4978), %s, %s, %s);\n",
    "                \"\"\"\n",
    "            cursor.execute(\n",
    "                insert_query, \n",
    "                (\n",
    "                    sat[\"scc\"], \n",
    "                    str(sat[\"ecef\"][0]), \n",
    "                    str(sat[\"ecef\"][1]), \n",
    "                    str(sat[\"ecef\"][2]), \n",
    "                    sat[\"timestamp\"], \n",
    "                    sat[\"name\"], \n",
    "                    sat[\"hilbert_index\"],\n",
    "                )\n",
    "            )\n",
    "        connection.commit()\n",
    "    cursor.close()\n",
    "    print(\"Satellite data inserted into the database.\")\n",
    "\n",
    "def main():\n",
    "    # Load satellite data\n",
    "    sats = get_starlink_satellites()\n",
    "\n",
    "    # Compute ECEF positions\n",
    "    sats = compute_ecef_positions(sats)\n",
    "\n",
    "    # compute hilbert index\n",
    "    world_size = 80_000_000\n",
    "    cell_size= 10_000\n",
    "    \n",
    "    hilbert_dict = {\n",
    "        \"world_size\":world_size,\n",
    "        \"cell_size\":cell_size,\n",
    "        \"n\":3,\n",
    "    }\n",
    "    hilbert = ecef_points_to_hilbert(np.array([s[\"ecef\"] for s in sats]),hilbert_dict)\n",
    "    sats = add_hilbert_to_satellites(sats,hilbert)\n",
    "\n",
    "    hilbert_ecef = hilbert_to_ecef_points(hilbert,hilbert_dict)\n",
    "    hilbert_points = [{\"hilbert\":hilbert[i],\"ecef\":hilbert_ecef[i]} for i in range(len(hilbert))]\n",
    "    \n",
    "    # Connect to the database\n",
    "    conn = connect_to_db()\n",
    "\n",
    "    # Insert hilbert index into the database\n",
    "    insert_hilbert_points(hilbert_points,conn)\n",
    "    \n",
    "    # Insert data into the database\n",
    "    insert_satellites(sats, conn)\n",
    "\n",
    "    # Close the connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc62aba-7a35-4df8-bf9e-2ec0168c99d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3b872-401a-4ec1-b8f9-63345cc60b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sats = get_starlink_satellites()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba680a4-53bf-4bb0-a3ec-e789f23dc732",
   "metadata": {},
   "outputs": [],
   "source": [
    "sats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71534d-4b97-48cf-9dcb-179fe7faf494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sats = compute_ecef_positions(sats)\n",
    "sats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e740245-c4c9-4118-8946-5a44bb9d23cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 80_000_000\n",
    "cell_size= 10_000\n",
    "\n",
    "hilbert_dict = {\n",
    "    \"world_size\":world_size,\n",
    "    \"cell_size\":cell_size,\n",
    "    \"n\":3,\n",
    "}\n",
    "\n",
    "hilbert_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ee2d0-0bdf-4927-be2c-72d9226c10c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hilbert = ecef_points_to_hilbert(np.array([s[\"ecef\"] for s in sats]),hilbert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ddd0e3-252b-464d-b08c-44411dd48194",
   "metadata": {},
   "outputs": [],
   "source": [
    "hilbert_ecef = hilbert_to_ecef_points(hilbert,hilbert_dict)\n",
    "hilbert_points = [{\"hilbert\":hilbert[i],\"ecef\":hilbert_ecef[i]} for i in range(len(hilbert))]\n",
    "hilbert_points[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7bbe3a-e2da-4644-96d8-4579cdc644a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sats = add_hilbert_to_satellites(sats,hilbert)\n",
    "sats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb951fa1-a69f-4f67-b03e-6496fe558db9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_satellites_table(conn)\n",
    "create_hilbert_points_table(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6edb70e-8994-4792-9f85-58d6bd638545",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_satellites_table(conn)\n",
    "drop_hilbert_points_table(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bba4ad-5601-4673-917a-372f2b08e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_hilbert_points(hilbert_points,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6fbf9-b083-453d-8409-78f2e406cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hilbert_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bafd5d9-09af-41a9-aea7-f17655511ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT COUNT(*) FROM hilbert_points;\"\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b2fb3-a5cb-4af9-a766-a19046b736b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_satellites(sats,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a916be6-117f-43ba-9bd6-633fa02bd909",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT COUNT(*) FROM satellites;\"\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query)\n",
    "cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9b3989-acde-4456-a0c7-a3ddc469ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2fec60-e65c-4f90-9f1a-202da4ee87a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
